{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL SPECIFICATION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "train_size = 4000\n",
    "shuffle_buffer = 100000\n",
    "total_epochs = 6000\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step decay for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_learning_rate = 0.1\n",
    "    drop = 0.1\n",
    "    epochs_drop = 500.0\n",
    "    lrate = initial_learning_rate * math.pow(drop,  \n",
    "           math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early stopping spec\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=1)\n",
    "#Learning schedule\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(step_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We download the MNIST Data from TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[-train_size:]\n",
    "y_train = y_train[-train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST data are 28x28 grayscale images. Each pixel can get a value from 0 to 255 thus we divide by 255 to normalise to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We normalise the data\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in x_train 4000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to \"one-hot\" vectors using the to_categorical function\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We train the Neural Networks according to the paper specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_size = [3000, 5000, 10000, 20000, \n",
    "                  22000, 25000, 27000, 30000, 32000, 35000, 37000,\n",
    "                40000, 50000, 60000, 70000, 80000, 100000, 300000, 800000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to compute the number of hidden units $H$ corresponding to each parameter $w$.\n",
    "\n",
    "$$ H  = \\frac{w-K}{d+K+1} $$\n",
    "\n",
    "where $d=784$ is the dimension of the input layer and $K=10$ that of the output layer. We also recall that the interpolation threshold can be found by \n",
    "\n",
    "$$ n\\times K = 4\\cdot 10^{3} \\times 10= 4\\cdot 10^{4}$$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784 #28*28\n",
    "interpol_threshold = num_classes * train_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the following empirical risk\n",
    "\n",
    "$$ \\frac{1}{n} \\sum_{i=1}^{n}l(h(x_{i}),y_{i})$$\n",
    "\n",
    "where $l(y',y) = (y'-y)^{2}$ is the squared loss function and $h(x)$ is our fully connected network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Weight Reuse Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Parameter:3000, RUN:1\n",
      "Testing Parameter:3000, RUN:1\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0693 - accuracy: 0.4277\n",
      "Completed Parameter:3000, RUN:1\n",
      "Fitting Parameter:5000, RUN:1\n",
      "Testing Parameter:5000, RUN:1\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0536 - accuracy: 0.6593\n",
      "Completed Parameter:5000, RUN:1\n",
      "Fitting Parameter:10000, RUN:1\n",
      "Testing Parameter:10000, RUN:1\n",
      "10000/10000 [==============================] - 1s 101us/sample - loss: 0.0443 - accuracy: 0.8277\n",
      "Completed Parameter:10000, RUN:1\n",
      "Fitting Parameter:20000, RUN:1\n",
      "Testing Parameter:20000, RUN:1\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0442 - accuracy: 0.8346\n",
      "Completed Parameter:20000, RUN:1\n",
      "Fitting Parameter:22000, RUN:1\n",
      "Testing Parameter:22000, RUN:1\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 0.0442 - accuracy: 0.8286\n",
      "Completed Parameter:22000, RUN:1\n",
      "Fitting Parameter:25000, RUN:1\n",
      "Testing Parameter:25000, RUN:1\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0450 - accuracy: 0.8319\n",
      "Completed Parameter:25000, RUN:1\n",
      "Fitting Parameter:27000, RUN:1\n",
      "Testing Parameter:27000, RUN:1\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0453 - accuracy: 0.8279\n",
      "Completed Parameter:27000, RUN:1\n",
      "Fitting Parameter:30000, RUN:1\n",
      "Testing Parameter:30000, RUN:1\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0441 - accuracy: 0.8235\n",
      "Completed Parameter:30000, RUN:1\n",
      "Fitting Parameter:32000, RUN:1\n",
      "Testing Parameter:32000, RUN:1\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0440 - accuracy: 0.8347\n",
      "Completed Parameter:32000, RUN:1\n",
      "Fitting Parameter:35000, RUN:1\n",
      "Testing Parameter:35000, RUN:1\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0462 - accuracy: 0.8331\n",
      "Completed Parameter:35000, RUN:1\n",
      "Fitting Parameter:37000, RUN:1\n",
      "Testing Parameter:37000, RUN:1\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0454 - accuracy: 0.8238\n",
      "Completed Parameter:37000, RUN:1\n",
      "Fitting Parameter:40000, RUN:1\n",
      "Testing Parameter:40000, RUN:1\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0456 - accuracy: 0.8101\n",
      "Completed Parameter:40000, RUN:1\n",
      "Fitting Parameter:50000, RUN:1\n",
      "Testing Parameter:50000, RUN:1\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0443 - accuracy: 0.8245\n",
      "Completed Parameter:50000, RUN:1\n",
      "Fitting Parameter:60000, RUN:1\n",
      "Testing Parameter:60000, RUN:1\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0459 - accuracy: 0.8157\n",
      "Completed Parameter:60000, RUN:1\n",
      "Fitting Parameter:70000, RUN:1\n",
      "Testing Parameter:70000, RUN:1\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0446 - accuracy: 0.8287\n",
      "Completed Parameter:70000, RUN:1\n",
      "Fitting Parameter:80000, RUN:1\n",
      "Testing Parameter:80000, RUN:1\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0436 - accuracy: 0.8362\n",
      "Completed Parameter:80000, RUN:1\n",
      "Fitting Parameter:100000, RUN:1\n",
      "Testing Parameter:100000, RUN:1\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 0.0451 - accuracy: 0.8249\n",
      "Completed Parameter:100000, RUN:1\n",
      "Fitting Parameter:300000, RUN:1\n",
      "Testing Parameter:300000, RUN:1\n",
      "10000/10000 [==============================] - 1s 125us/sample - loss: 0.0468 - accuracy: 0.8209\n",
      "Completed Parameter:300000, RUN:1\n",
      "Fitting Parameter:800000, RUN:1\n",
      "Testing Parameter:800000, RUN:1\n",
      "10000/10000 [==============================] - 1s 142us/sample - loss: 0.0489 - accuracy: 0.8081\n",
      "Completed Parameter:800000, RUN:1\n",
      "Fitting Parameter:3000, RUN:2\n",
      "Testing Parameter:3000, RUN:2\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0687 - accuracy: 0.4979\n",
      "Completed Parameter:3000, RUN:2\n",
      "Fitting Parameter:5000, RUN:2\n",
      "Testing Parameter:5000, RUN:2\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0534 - accuracy: 0.6773\n",
      "Completed Parameter:5000, RUN:2\n",
      "Fitting Parameter:10000, RUN:2\n",
      "Testing Parameter:10000, RUN:2\n",
      "10000/10000 [==============================] - 1s 101us/sample - loss: 0.0450 - accuracy: 0.8212\n",
      "Completed Parameter:10000, RUN:2\n",
      "Fitting Parameter:20000, RUN:2\n",
      "Testing Parameter:20000, RUN:2\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0440 - accuracy: 0.8426\n",
      "Completed Parameter:20000, RUN:2\n",
      "Fitting Parameter:22000, RUN:2\n",
      "Testing Parameter:22000, RUN:2\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 0.0458 - accuracy: 0.8150\n",
      "Completed Parameter:22000, RUN:2\n",
      "Fitting Parameter:25000, RUN:2\n",
      "Testing Parameter:25000, RUN:2\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 0.0451 - accuracy: 0.8368\n",
      "Completed Parameter:25000, RUN:2\n",
      "Fitting Parameter:27000, RUN:2\n",
      "Testing Parameter:27000, RUN:2\n",
      "10000/10000 [==============================] - 1s 113us/sample - loss: 0.0443 - accuracy: 0.8392\n",
      "Completed Parameter:27000, RUN:2\n",
      "Fitting Parameter:30000, RUN:2\n",
      "Testing Parameter:30000, RUN:2\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0439 - accuracy: 0.8343\n",
      "Completed Parameter:30000, RUN:2\n",
      "Fitting Parameter:32000, RUN:2\n",
      "Testing Parameter:32000, RUN:2\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 0.0445 - accuracy: 0.8192\n",
      "Completed Parameter:32000, RUN:2\n",
      "Fitting Parameter:35000, RUN:2\n",
      "Testing Parameter:35000, RUN:2\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0446 - accuracy: 0.8233\n",
      "Completed Parameter:35000, RUN:2\n",
      "Fitting Parameter:37000, RUN:2\n",
      "Testing Parameter:37000, RUN:2\n",
      "10000/10000 [==============================] - 1s 114us/sample - loss: 0.0452 - accuracy: 0.8254\n",
      "Completed Parameter:37000, RUN:2\n",
      "Fitting Parameter:40000, RUN:2\n",
      "Testing Parameter:40000, RUN:2\n",
      "10000/10000 [==============================] - 1s 113us/sample - loss: 0.0432 - accuracy: 0.8446\n",
      "Completed Parameter:40000, RUN:2\n",
      "Fitting Parameter:50000, RUN:2\n",
      "Testing Parameter:50000, RUN:2\n",
      "10000/10000 [==============================] - 1s 114us/sample - loss: 0.0452 - accuracy: 0.8273\n",
      "Completed Parameter:50000, RUN:2\n",
      "Fitting Parameter:60000, RUN:2\n",
      "Testing Parameter:60000, RUN:2\n",
      "10000/10000 [==============================] - 1s 115us/sample - loss: 0.0441 - accuracy: 0.8326\n",
      "Completed Parameter:60000, RUN:2\n",
      "Fitting Parameter:70000, RUN:2\n",
      "Testing Parameter:70000, RUN:2\n",
      "10000/10000 [==============================] - 1s 113us/sample - loss: 0.0441 - accuracy: 0.8233\n",
      "Completed Parameter:70000, RUN:2\n",
      "Fitting Parameter:80000, RUN:2\n",
      "Testing Parameter:80000, RUN:2\n",
      "10000/10000 [==============================] - 1s 117us/sample - loss: 0.0446 - accuracy: 0.8231\n",
      "Completed Parameter:80000, RUN:2\n",
      "Fitting Parameter:100000, RUN:2\n",
      "Testing Parameter:100000, RUN:2\n",
      "10000/10000 [==============================] - 1s 118us/sample - loss: 0.0463 - accuracy: 0.8149\n",
      "Completed Parameter:100000, RUN:2\n",
      "Fitting Parameter:300000, RUN:2\n",
      "Testing Parameter:300000, RUN:2\n",
      "10000/10000 [==============================] - 1s 131us/sample - loss: 0.0470 - accuracy: 0.8113\n",
      "Completed Parameter:300000, RUN:2\n",
      "Fitting Parameter:800000, RUN:2\n",
      "Testing Parameter:800000, RUN:2\n",
      "10000/10000 [==============================] - 2s 162us/sample - loss: 0.0495 - accuracy: 0.8083\n",
      "Completed Parameter:800000, RUN:2\n",
      "Fitting Parameter:3000, RUN:3\n",
      "Testing Parameter:3000, RUN:3\n",
      "10000/10000 [==============================] - 1s 114us/sample - loss: 0.0688 - accuracy: 0.4747\n",
      "Completed Parameter:3000, RUN:3\n",
      "Fitting Parameter:5000, RUN:3\n",
      "Testing Parameter:5000, RUN:3\n",
      "10000/10000 [==============================] - 1s 114us/sample - loss: 0.0532 - accuracy: 0.6929\n",
      "Completed Parameter:5000, RUN:3\n",
      "Fitting Parameter:10000, RUN:3\n",
      "Testing Parameter:10000, RUN:3\n",
      "10000/10000 [==============================] - 1s 115us/sample - loss: 0.0449 - accuracy: 0.8197\n",
      "Completed Parameter:10000, RUN:3\n",
      "Fitting Parameter:20000, RUN:3\n",
      "Testing Parameter:20000, RUN:3\n",
      "10000/10000 [==============================] - 1s 117us/sample - loss: 0.0440 - accuracy: 0.8284\n",
      "Completed Parameter:20000, RUN:3\n",
      "Fitting Parameter:22000, RUN:3\n",
      "Testing Parameter:22000, RUN:3\n",
      "10000/10000 [==============================] - 1s 116us/sample - loss: 0.0440 - accuracy: 0.8330\n",
      "Completed Parameter:22000, RUN:3\n",
      "Fitting Parameter:25000, RUN:3\n",
      "Testing Parameter:25000, RUN:3\n",
      "10000/10000 [==============================] - 1s 117us/sample - loss: 0.0435 - accuracy: 0.8316\n",
      "Completed Parameter:25000, RUN:3\n",
      "Fitting Parameter:27000, RUN:3\n",
      "Testing Parameter:27000, RUN:3\n",
      "10000/10000 [==============================] - 1s 116us/sample - loss: 0.0440 - accuracy: 0.8245\n",
      "Completed Parameter:27000, RUN:3\n",
      "Fitting Parameter:30000, RUN:3\n",
      "Testing Parameter:30000, RUN:3\n",
      "10000/10000 [==============================] - 1s 120us/sample - loss: 0.0448 - accuracy: 0.8234\n",
      "Completed Parameter:30000, RUN:3\n",
      "Fitting Parameter:32000, RUN:3\n",
      "Testing Parameter:32000, RUN:3\n",
      "10000/10000 [==============================] - 1s 116us/sample - loss: 0.0433 - accuracy: 0.8389\n",
      "Completed Parameter:32000, RUN:3\n",
      "Fitting Parameter:35000, RUN:3\n",
      "Testing Parameter:35000, RUN:3\n",
      "10000/10000 [==============================] - 1s 117us/sample - loss: 0.0450 - accuracy: 0.8208\n",
      "Completed Parameter:35000, RUN:3\n",
      "Fitting Parameter:37000, RUN:3\n",
      "Testing Parameter:37000, RUN:3\n",
      "10000/10000 [==============================] - 1s 116us/sample - loss: 0.0446 - accuracy: 0.8199\n",
      "Completed Parameter:37000, RUN:3\n",
      "Fitting Parameter:40000, RUN:3\n",
      "Testing Parameter:40000, RUN:3\n",
      "10000/10000 [==============================] - 1s 116us/sample - loss: 0.0444 - accuracy: 0.8290\n",
      "Completed Parameter:40000, RUN:3\n",
      "Fitting Parameter:50000, RUN:3\n",
      "Testing Parameter:50000, RUN:3\n",
      "10000/10000 [==============================] - 1s 120us/sample - loss: 0.0440 - accuracy: 0.8340\n",
      "Completed Parameter:50000, RUN:3\n",
      "Fitting Parameter:60000, RUN:3\n",
      "Testing Parameter:60000, RUN:3\n",
      "10000/10000 [==============================] - 1s 119us/sample - loss: 0.0442 - accuracy: 0.8337\n",
      "Completed Parameter:60000, RUN:3\n",
      "Fitting Parameter:70000, RUN:3\n",
      "Testing Parameter:70000, RUN:3\n",
      "10000/10000 [==============================] - 1s 118us/sample - loss: 0.0450 - accuracy: 0.8353\n",
      "Completed Parameter:70000, RUN:3\n",
      "Fitting Parameter:80000, RUN:3\n",
      "Testing Parameter:80000, RUN:3\n",
      "10000/10000 [==============================] - 1s 121us/sample - loss: 0.0451 - accuracy: 0.8252\n",
      "Completed Parameter:80000, RUN:3\n",
      "Fitting Parameter:100000, RUN:3\n",
      "Testing Parameter:100000, RUN:3\n",
      "10000/10000 [==============================] - 1s 122us/sample - loss: 0.0456 - accuracy: 0.8189\n",
      "Completed Parameter:100000, RUN:3\n",
      "Fitting Parameter:300000, RUN:3\n",
      "Testing Parameter:300000, RUN:3\n",
      "10000/10000 [==============================] - 1s 137us/sample - loss: 0.0463 - accuracy: 0.8277\n",
      "Completed Parameter:300000, RUN:3\n",
      "Fitting Parameter:800000, RUN:3\n",
      "Testing Parameter:800000, RUN:3\n",
      "10000/10000 [==============================] - 2s 160us/sample - loss: 0.0471 - accuracy: 0.8146\n",
      "Completed Parameter:800000, RUN:3\n",
      "Fitting Parameter:3000, RUN:4\n",
      "Testing Parameter:3000, RUN:4\n",
      "10000/10000 [==============================] - 1s 113us/sample - loss: 0.0689 - accuracy: 0.5108\n",
      "Completed Parameter:3000, RUN:4\n",
      "Fitting Parameter:5000, RUN:4\n",
      "Testing Parameter:5000, RUN:4\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0537 - accuracy: 0.6870\n",
      "Completed Parameter:5000, RUN:4\n",
      "Fitting Parameter:10000, RUN:4\n",
      "Testing Parameter:10000, RUN:4\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0450 - accuracy: 0.8364\n",
      "Completed Parameter:10000, RUN:4\n",
      "Fitting Parameter:20000, RUN:4\n",
      "Testing Parameter:20000, RUN:4\n",
      "10000/10000 [==============================] - 1s 114us/sample - loss: 0.0448 - accuracy: 0.8101\n",
      "Completed Parameter:20000, RUN:4\n",
      "Fitting Parameter:22000, RUN:4\n",
      "Testing Parameter:22000, RUN:4\n",
      "10000/10000 [==============================] - 1s 114us/sample - loss: 0.0436 - accuracy: 0.8276\n",
      "Completed Parameter:22000, RUN:4\n",
      "Fitting Parameter:25000, RUN:4\n",
      "Testing Parameter:25000, RUN:4\n",
      "10000/10000 [==============================] - 1s 113us/sample - loss: 0.0447 - accuracy: 0.8164\n",
      "Completed Parameter:25000, RUN:4\n",
      "Fitting Parameter:27000, RUN:4\n",
      "Testing Parameter:27000, RUN:4\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 0.0448 - accuracy: 0.8256\n",
      "Completed Parameter:27000, RUN:4\n",
      "Fitting Parameter:30000, RUN:4\n",
      "Testing Parameter:30000, RUN:4\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0449 - accuracy: 0.8296\n",
      "Completed Parameter:30000, RUN:4\n",
      "Fitting Parameter:32000, RUN:4\n",
      "Testing Parameter:32000, RUN:4\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0452 - accuracy: 0.8268\n",
      "Completed Parameter:32000, RUN:4\n",
      "Fitting Parameter:35000, RUN:4\n",
      "Testing Parameter:35000, RUN:4\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0435 - accuracy: 0.8370\n",
      "Completed Parameter:35000, RUN:4\n",
      "Fitting Parameter:37000, RUN:4\n",
      "Testing Parameter:37000, RUN:4\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0443 - accuracy: 0.8288\n",
      "Completed Parameter:37000, RUN:4\n",
      "Fitting Parameter:40000, RUN:4\n",
      "Testing Parameter:40000, RUN:4\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0441 - accuracy: 0.8382\n",
      "Completed Parameter:40000, RUN:4\n",
      "Fitting Parameter:50000, RUN:4\n",
      "Testing Parameter:50000, RUN:4\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0443 - accuracy: 0.8362\n",
      "Completed Parameter:50000, RUN:4\n",
      "Fitting Parameter:60000, RUN:4\n",
      "Testing Parameter:60000, RUN:4\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0439 - accuracy: 0.8251\n",
      "Completed Parameter:60000, RUN:4\n",
      "Fitting Parameter:70000, RUN:4\n",
      "Testing Parameter:70000, RUN:4\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0447 - accuracy: 0.8222\n",
      "Completed Parameter:70000, RUN:4\n",
      "Fitting Parameter:80000, RUN:4\n",
      "Testing Parameter:80000, RUN:4\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0446 - accuracy: 0.8228\n",
      "Completed Parameter:80000, RUN:4\n",
      "Fitting Parameter:100000, RUN:4\n",
      "Testing Parameter:100000, RUN:4\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0484 - accuracy: 0.7954\n",
      "Completed Parameter:100000, RUN:4\n",
      "Fitting Parameter:300000, RUN:4\n",
      "Testing Parameter:300000, RUN:4\n",
      "10000/10000 [==============================] - 1s 128us/sample - loss: 0.0476 - accuracy: 0.8063\n",
      "Completed Parameter:300000, RUN:4\n",
      "Fitting Parameter:800000, RUN:4\n",
      "Testing Parameter:800000, RUN:4\n",
      "10000/10000 [==============================] - 1s 148us/sample - loss: 0.0511 - accuracy: 0.8070\n",
      "Completed Parameter:800000, RUN:4\n",
      "Fitting Parameter:3000, RUN:5\n",
      "Testing Parameter:3000, RUN:5\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0688 - accuracy: 0.4383\n",
      "Completed Parameter:3000, RUN:5\n",
      "Fitting Parameter:5000, RUN:5\n",
      "Testing Parameter:5000, RUN:5\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 0.0540 - accuracy: 0.6988\n",
      "Completed Parameter:5000, RUN:5\n",
      "Fitting Parameter:10000, RUN:5\n",
      "Testing Parameter:10000, RUN:5\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0447 - accuracy: 0.8358\n",
      "Completed Parameter:10000, RUN:5\n",
      "Fitting Parameter:20000, RUN:5\n",
      "Testing Parameter:20000, RUN:5\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 0.0445 - accuracy: 0.8173\n",
      "Completed Parameter:20000, RUN:5\n",
      "Fitting Parameter:22000, RUN:5\n",
      "Testing Parameter:22000, RUN:5\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0445 - accuracy: 0.8364\n",
      "Completed Parameter:22000, RUN:5\n",
      "Fitting Parameter:25000, RUN:5\n",
      "Testing Parameter:25000, RUN:5\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 0.0435 - accuracy: 0.8253\n",
      "Completed Parameter:25000, RUN:5\n",
      "Fitting Parameter:27000, RUN:5\n",
      "Testing Parameter:27000, RUN:5\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0451 - accuracy: 0.8246\n",
      "Completed Parameter:27000, RUN:5\n",
      "Fitting Parameter:30000, RUN:5\n",
      "Testing Parameter:30000, RUN:5\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 0.0458 - accuracy: 0.8274\n",
      "Completed Parameter:30000, RUN:5\n",
      "Fitting Parameter:32000, RUN:5\n",
      "Testing Parameter:32000, RUN:5\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0445 - accuracy: 0.8190\n",
      "Completed Parameter:32000, RUN:5\n",
      "Fitting Parameter:35000, RUN:5\n",
      "Testing Parameter:35000, RUN:5\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0452 - accuracy: 0.8282\n",
      "Completed Parameter:35000, RUN:5\n",
      "Fitting Parameter:37000, RUN:5\n",
      "Testing Parameter:37000, RUN:5\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0457 - accuracy: 0.8235\n",
      "Completed Parameter:37000, RUN:5\n",
      "Fitting Parameter:40000, RUN:5\n",
      "Testing Parameter:40000, RUN:5\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0453 - accuracy: 0.8366\n",
      "Completed Parameter:40000, RUN:5\n",
      "Fitting Parameter:50000, RUN:5\n",
      "Testing Parameter:50000, RUN:5\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0443 - accuracy: 0.8331\n",
      "Completed Parameter:50000, RUN:5\n",
      "Fitting Parameter:60000, RUN:5\n",
      "Testing Parameter:60000, RUN:5\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0447 - accuracy: 0.8417\n",
      "Completed Parameter:60000, RUN:5\n",
      "Fitting Parameter:70000, RUN:5\n",
      "Testing Parameter:70000, RUN:5\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 0.0459 - accuracy: 0.8069\n",
      "Completed Parameter:70000, RUN:5\n",
      "Fitting Parameter:80000, RUN:5\n",
      "Testing Parameter:80000, RUN:5\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 0.0444 - accuracy: 0.8324\n",
      "Completed Parameter:80000, RUN:5\n",
      "Fitting Parameter:100000, RUN:5\n",
      "Testing Parameter:100000, RUN:5\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0448 - accuracy: 0.8312\n",
      "Completed Parameter:100000, RUN:5\n",
      "Fitting Parameter:300000, RUN:5\n",
      "Testing Parameter:300000, RUN:5\n",
      "10000/10000 [==============================] - 1s 125us/sample - loss: 0.0451 - accuracy: 0.8153\n",
      "Completed Parameter:300000, RUN:5\n",
      "Fitting Parameter:800000, RUN:5\n",
      "Testing Parameter:800000, RUN:5\n",
      "10000/10000 [==============================] - 1s 150us/sample - loss: 0.0478 - accuracy: 0.8176\n",
      "Completed Parameter:800000, RUN:5\n"
     ]
    }
   ],
   "source": [
    "training_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "for run in range(1,6):\n",
    "    training_loss = []\n",
    "    test_loss = []\n",
    "    training_dict  = {}\n",
    "    test_dict  = {}\n",
    "    for parameters in parameter_size:\n",
    "        train_loss = tf.keras.losses.MeanSquaredError(name = \"train_loss\")\n",
    "        sgd_optimizer = tf.keras.optimizers.SGD(momentum=0.95)\n",
    "        #Gives number of units from number of weights\n",
    "        units = tl.get_number_units(parameters, input_size = input_size, output_size = num_classes)\n",
    "        if units == 3000:\n",
    "            network = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),#We flatten the images to vector of size 784\n",
    "            tf.keras.layers.Dense(units=units, activation = None),#Hidden Layer\n",
    "            tf.keras.layers.Dense(units=num_classes, activation = None)#Output Layer\n",
    "            ])\n",
    "        elif units < interpol_threshold and units > 3000 :\n",
    "            network = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(units=units, bias_initializer = tf.constant_initializer(tl.custom_bias(units,hidden_bias_wgts)),\n",
    "                                kernel_initializer = tf.constant_initializer(tl.custom_kernel(units,hidden_kernel_wgts)),  activation = None),\n",
    "            tf.keras.layers.Dense(units=num_classes, bias_initializer = tf.constant_initializer(tl.custom_bias(units,hidden_bias_wgts)),\n",
    "                                kernel_initializer = tf.constant_initializer(tl.custom_kernel(units,hidden_kernel_wgts)),  activation = None)])\n",
    "        else:\n",
    "            network = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(units=units, activation = None),\n",
    "            tf.keras.layers.Dense(units=num_classes,  activation = None)])\n",
    "            #Training\n",
    "        network.compile(optimizer = sgd_optimizer, loss = train_loss , metrics = ['accuracy'])\n",
    "        print(\"Fitting Parameter:{}, RUN:{}\".format(parameters,run))\n",
    "        if units < interpol_threshold:\n",
    "            history = network.fit(x=x_train, y=y_train, callbacks=[earlystop_callback,lr_schedule], epochs=total_epochs, verbose = 0)\n",
    "        else:\n",
    "            history = network.fit(x=x_train, y=y_train, epochs=total_epochs, verbose = 0)\n",
    "        if units <= interpol_threshold:\n",
    "            hidden_kernel_wgts = network.get_weights()[0]\n",
    "            hidden_bias_wgts = network.get_weights()[1]\n",
    "            output_kernel_wgts = network.get_weights()[2]\n",
    "            output_bias_wgts = network.get_weights()[3]\n",
    "        training_loss.append(history.history[\"loss\"][-1])\n",
    "        print(\"Testing Parameter:{}, RUN:{}\".format(parameters,run))\n",
    "        results = network.evaluate(x_test, y_test)\n",
    "        test_loss.append(results[0])\n",
    "        print(\"Completed Parameter:{}, RUN:{}\".format(parameters,run))\n",
    "    training_df[str(run)] = training_loss\n",
    "    test_df[str(run)] = test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.067534</td>\n",
       "      <td>0.066944</td>\n",
       "      <td>0.067069</td>\n",
       "      <td>0.066947</td>\n",
       "      <td>0.067487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.048965</td>\n",
       "      <td>0.048030</td>\n",
       "      <td>0.049502</td>\n",
       "      <td>0.049260</td>\n",
       "      <td>0.049355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.036903</td>\n",
       "      <td>0.037807</td>\n",
       "      <td>0.035573</td>\n",
       "      <td>0.037046</td>\n",
       "      <td>0.035390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.035736</td>\n",
       "      <td>0.036491</td>\n",
       "      <td>0.036016</td>\n",
       "      <td>0.036878</td>\n",
       "      <td>0.035642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.036140</td>\n",
       "      <td>0.036180</td>\n",
       "      <td>0.035525</td>\n",
       "      <td>0.036541</td>\n",
       "      <td>0.037255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5\n",
       "0  0.067534  0.066944  0.067069  0.066947  0.067487\n",
       "1  0.048965  0.048030  0.049502  0.049260  0.049355\n",
       "2  0.036903  0.037807  0.035573  0.037046  0.035390\n",
       "3  0.035736  0.036491  0.036016  0.036878  0.035642\n",
       "4  0.036140  0.036180  0.035525  0.036541  0.037255"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.069320</td>\n",
       "      <td>0.068688</td>\n",
       "      <td>0.068839</td>\n",
       "      <td>0.068930</td>\n",
       "      <td>0.068793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.053619</td>\n",
       "      <td>0.053389</td>\n",
       "      <td>0.053245</td>\n",
       "      <td>0.053740</td>\n",
       "      <td>0.053951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.044327</td>\n",
       "      <td>0.044988</td>\n",
       "      <td>0.044918</td>\n",
       "      <td>0.045019</td>\n",
       "      <td>0.044732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.044224</td>\n",
       "      <td>0.044019</td>\n",
       "      <td>0.043960</td>\n",
       "      <td>0.044775</td>\n",
       "      <td>0.044518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.044170</td>\n",
       "      <td>0.045837</td>\n",
       "      <td>0.043995</td>\n",
       "      <td>0.043632</td>\n",
       "      <td>0.044517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5\n",
       "0  0.069320  0.068688  0.068839  0.068930  0.068793\n",
       "1  0.053619  0.053389  0.053245  0.053740  0.053951\n",
       "2  0.044327  0.044988  0.044918  0.045019  0.044732\n",
       "3  0.044224  0.044019  0.043960  0.044775  0.044518\n",
       "4  0.044170  0.045837  0.043995  0.043632  0.044517"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(parameter_size, training_df.mean(axis=1), label=\"Training\", marker=\"o\")\n",
    "plt.plot(parameter_size, test_df.mean(axis=1), label=\"Test\", marker=\"o\")\n",
    "plt.yscale(value=\"log\")\n",
    "plt.legend()\n",
    "plt.xscale(value=\"log\")\n",
    "x_lbl = plt.xlabel(\"Number of Weights\")\n",
    "#y_lbl = plt.ylabel(\"Squared Loss\")\n",
    "plt.xlim(xmin=0)\n",
    "plt.axvline(x=40000, linestyle=\"--\", color = \"black\")\n",
    "plt.title(\"With Weight Reuse\")\n",
    "plt.savefig(\"with_reuse.png\",bbox_extra_artists=[x_lbl],dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Weight Reuse Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_df = pd.DataFrame()\n",
    "test_scores_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Parameter:3000, RUN:1\n",
      "Testing Parameter:3000, RUN:1\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0693 - accuracy: 0.5013\n",
      "Completed Parameter:3000, RUN:1\n",
      "Fitting Parameter:5000, RUN:1\n",
      "Testing Parameter:5000, RUN:1\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0533 - accuracy: 0.7179\n",
      "Completed Parameter:5000, RUN:1\n",
      "Fitting Parameter:10000, RUN:1\n",
      "Testing Parameter:10000, RUN:1\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0432 - accuracy: 0.8490\n",
      "Completed Parameter:10000, RUN:1\n",
      "Fitting Parameter:20000, RUN:1\n",
      "Testing Parameter:20000, RUN:1\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 0.0438 - accuracy: 0.8332\n",
      "Completed Parameter:20000, RUN:1\n",
      "Fitting Parameter:22000, RUN:1\n",
      "Testing Parameter:22000, RUN:1\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 0.0444 - accuracy: 0.8281\n",
      "Completed Parameter:22000, RUN:1\n",
      "Fitting Parameter:25000, RUN:1\n",
      "Testing Parameter:25000, RUN:1\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 0.0445 - accuracy: 0.8202\n",
      "Completed Parameter:25000, RUN:1\n",
      "Fitting Parameter:27000, RUN:1\n",
      "Testing Parameter:27000, RUN:1\n",
      "10000/10000 [==============================] - 1s 113us/sample - loss: 0.0447 - accuracy: 0.8188\n",
      "Completed Parameter:27000, RUN:1\n",
      "Fitting Parameter:30000, RUN:1\n",
      "Testing Parameter:30000, RUN:1\n",
      "10000/10000 [==============================] - 1s 115us/sample - loss: 0.0439 - accuracy: 0.8290\n",
      "Completed Parameter:30000, RUN:1\n",
      "Fitting Parameter:32000, RUN:1\n",
      "Testing Parameter:32000, RUN:1\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0447 - accuracy: 0.8135\n",
      "Completed Parameter:32000, RUN:1\n",
      "Fitting Parameter:35000, RUN:1\n",
      "Testing Parameter:35000, RUN:1\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0465 - accuracy: 0.8203\n",
      "Completed Parameter:35000, RUN:1\n",
      "Fitting Parameter:37000, RUN:1\n",
      "Testing Parameter:37000, RUN:1\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0444 - accuracy: 0.8265\n",
      "Completed Parameter:37000, RUN:1\n",
      "Fitting Parameter:40000, RUN:1\n",
      "Testing Parameter:40000, RUN:1\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0439 - accuracy: 0.8246\n",
      "Completed Parameter:40000, RUN:1\n",
      "Fitting Parameter:50000, RUN:1\n",
      "Testing Parameter:50000, RUN:1\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0448 - accuracy: 0.8185\n",
      "Completed Parameter:50000, RUN:1\n",
      "Fitting Parameter:60000, RUN:1\n",
      "Testing Parameter:60000, RUN:1\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0442 - accuracy: 0.8316\n",
      "Completed Parameter:60000, RUN:1\n",
      "Fitting Parameter:70000, RUN:1\n",
      "Testing Parameter:70000, RUN:1\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 0.0454 - accuracy: 0.8160\n",
      "Completed Parameter:70000, RUN:1\n",
      "Fitting Parameter:80000, RUN:1\n",
      "Testing Parameter:80000, RUN:1\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 0.0455 - accuracy: 0.8230\n",
      "Completed Parameter:80000, RUN:1\n",
      "Fitting Parameter:100000, RUN:1\n",
      "Testing Parameter:100000, RUN:1\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 0.0443 - accuracy: 0.8402\n",
      "Completed Parameter:100000, RUN:1\n",
      "Fitting Parameter:300000, RUN:1\n",
      "Testing Parameter:300000, RUN:1\n",
      "10000/10000 [==============================] - 1s 124us/sample - loss: 0.0470 - accuracy: 0.8159\n",
      "Completed Parameter:300000, RUN:1\n",
      "Fitting Parameter:800000, RUN:1\n",
      "Testing Parameter:800000, RUN:1\n",
      "10000/10000 [==============================] - 1s 146us/sample - loss: 0.0460 - accuracy: 0.8206\n",
      "Completed Parameter:800000, RUN:1\n",
      "Fitting Parameter:3000, RUN:2\n",
      "Testing Parameter:3000, RUN:2\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0687 - accuracy: 0.5073\n",
      "Completed Parameter:3000, RUN:2\n",
      "Fitting Parameter:5000, RUN:2\n",
      "Testing Parameter:5000, RUN:2\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0538 - accuracy: 0.6848\n",
      "Completed Parameter:5000, RUN:2\n",
      "Fitting Parameter:10000, RUN:2\n",
      "Testing Parameter:10000, RUN:2\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0433 - accuracy: 0.8401\n",
      "Completed Parameter:10000, RUN:2\n",
      "Fitting Parameter:20000, RUN:2\n",
      "Testing Parameter:20000, RUN:2\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0456 - accuracy: 0.8288\n",
      "Completed Parameter:20000, RUN:2\n",
      "Fitting Parameter:22000, RUN:2\n",
      "Testing Parameter:22000, RUN:2\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0445 - accuracy: 0.8272\n",
      "Completed Parameter:22000, RUN:2\n",
      "Fitting Parameter:25000, RUN:2\n",
      "Testing Parameter:25000, RUN:2\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0457 - accuracy: 0.8238\n",
      "Completed Parameter:25000, RUN:2\n",
      "Fitting Parameter:27000, RUN:2\n",
      "Testing Parameter:27000, RUN:2\n",
      "10000/10000 [==============================] - 1s 114us/sample - loss: 0.0437 - accuracy: 0.8388\n",
      "Completed Parameter:27000, RUN:2\n",
      "Fitting Parameter:30000, RUN:2\n",
      "Testing Parameter:30000, RUN:2\n",
      "10000/10000 [==============================] - 1s 117us/sample - loss: 0.0435 - accuracy: 0.8411\n",
      "Completed Parameter:30000, RUN:2\n",
      "Fitting Parameter:32000, RUN:2\n",
      "Testing Parameter:32000, RUN:2\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 0.0438 - accuracy: 0.8259\n",
      "Completed Parameter:32000, RUN:2\n",
      "Fitting Parameter:35000, RUN:2\n",
      "Testing Parameter:35000, RUN:2\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 0.0432 - accuracy: 0.8319\n",
      "Completed Parameter:35000, RUN:2\n",
      "Fitting Parameter:37000, RUN:2\n",
      "Testing Parameter:37000, RUN:2\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0440 - accuracy: 0.8269\n",
      "Completed Parameter:37000, RUN:2\n",
      "Fitting Parameter:40000, RUN:2\n",
      "Testing Parameter:40000, RUN:2\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0440 - accuracy: 0.8306\n",
      "Completed Parameter:40000, RUN:2\n",
      "Fitting Parameter:50000, RUN:2\n",
      "Testing Parameter:50000, RUN:2\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0432 - accuracy: 0.8351\n",
      "Completed Parameter:50000, RUN:2\n",
      "Fitting Parameter:60000, RUN:2\n",
      "Testing Parameter:60000, RUN:2\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0446 - accuracy: 0.8269\n",
      "Completed Parameter:60000, RUN:2\n",
      "Fitting Parameter:70000, RUN:2\n",
      "Testing Parameter:70000, RUN:2\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 0.0444 - accuracy: 0.8196\n",
      "Completed Parameter:70000, RUN:2\n",
      "Fitting Parameter:80000, RUN:2\n",
      "Testing Parameter:80000, RUN:2\n",
      "10000/10000 [==============================] - 1s 113us/sample - loss: 0.0462 - accuracy: 0.8237\n",
      "Completed Parameter:80000, RUN:2\n",
      "Fitting Parameter:100000, RUN:2\n",
      "Testing Parameter:100000, RUN:2\n",
      "10000/10000 [==============================] - 1s 114us/sample - loss: 0.0450 - accuracy: 0.8179\n",
      "Completed Parameter:100000, RUN:2\n",
      "Fitting Parameter:300000, RUN:2\n",
      "Testing Parameter:300000, RUN:2\n",
      "10000/10000 [==============================] - 1s 126us/sample - loss: 0.0452 - accuracy: 0.8310\n",
      "Completed Parameter:300000, RUN:2\n",
      "Fitting Parameter:800000, RUN:2\n",
      "Testing Parameter:800000, RUN:2\n",
      "10000/10000 [==============================] - 1s 149us/sample - loss: 0.0455 - accuracy: 0.8139\n",
      "Completed Parameter:800000, RUN:2\n",
      "Fitting Parameter:3000, RUN:3\n",
      "Testing Parameter:3000, RUN:3\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0687 - accuracy: 0.5212\n",
      "Completed Parameter:3000, RUN:3\n",
      "Fitting Parameter:5000, RUN:3\n",
      "Testing Parameter:5000, RUN:3\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0551 - accuracy: 0.7097\n",
      "Completed Parameter:5000, RUN:3\n",
      "Fitting Parameter:10000, RUN:3\n",
      "Testing Parameter:10000, RUN:3\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0436 - accuracy: 0.8302\n",
      "Completed Parameter:10000, RUN:3\n",
      "Fitting Parameter:20000, RUN:3\n",
      "Testing Parameter:20000, RUN:3\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0451 - accuracy: 0.8201\n",
      "Completed Parameter:20000, RUN:3\n",
      "Fitting Parameter:22000, RUN:3\n",
      "Testing Parameter:22000, RUN:3\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0455 - accuracy: 0.8245\n",
      "Completed Parameter:22000, RUN:3\n",
      "Fitting Parameter:25000, RUN:3\n",
      "Testing Parameter:25000, RUN:3\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0436 - accuracy: 0.8336\n",
      "Completed Parameter:25000, RUN:3\n",
      "Fitting Parameter:27000, RUN:3\n",
      "Testing Parameter:27000, RUN:3\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0446 - accuracy: 0.8383\n",
      "Completed Parameter:27000, RUN:3\n",
      "Fitting Parameter:30000, RUN:3\n",
      "Testing Parameter:30000, RUN:3\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 0.0446 - accuracy: 0.8312\n",
      "Completed Parameter:30000, RUN:3\n",
      "Fitting Parameter:32000, RUN:3\n",
      "Testing Parameter:32000, RUN:3\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0452 - accuracy: 0.8149\n",
      "Completed Parameter:32000, RUN:3\n",
      "Fitting Parameter:35000, RUN:3\n",
      "Testing Parameter:35000, RUN:3\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0439 - accuracy: 0.8342\n",
      "Completed Parameter:35000, RUN:3\n",
      "Fitting Parameter:37000, RUN:3\n",
      "Testing Parameter:37000, RUN:3\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0440 - accuracy: 0.8372\n",
      "Completed Parameter:37000, RUN:3\n",
      "Fitting Parameter:40000, RUN:3\n",
      "Testing Parameter:40000, RUN:3\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0443 - accuracy: 0.8395\n",
      "Completed Parameter:40000, RUN:3\n",
      "Fitting Parameter:50000, RUN:3\n",
      "Testing Parameter:50000, RUN:3\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0448 - accuracy: 0.8202\n",
      "Completed Parameter:50000, RUN:3\n",
      "Fitting Parameter:60000, RUN:3\n",
      "Testing Parameter:60000, RUN:3\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0441 - accuracy: 0.8355\n",
      "Completed Parameter:60000, RUN:3\n",
      "Fitting Parameter:70000, RUN:3\n",
      "Testing Parameter:70000, RUN:3\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 0.0445 - accuracy: 0.8196\n",
      "Completed Parameter:70000, RUN:3\n",
      "Fitting Parameter:80000, RUN:3\n",
      "Testing Parameter:80000, RUN:3\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0448 - accuracy: 0.8266\n",
      "Completed Parameter:80000, RUN:3\n",
      "Fitting Parameter:100000, RUN:3\n",
      "Testing Parameter:100000, RUN:3\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0445 - accuracy: 0.8323\n",
      "Completed Parameter:100000, RUN:3\n",
      "Fitting Parameter:300000, RUN:3\n",
      "Testing Parameter:300000, RUN:3\n",
      "10000/10000 [==============================] - 1s 126us/sample - loss: 0.0469 - accuracy: 0.8276\n",
      "Completed Parameter:300000, RUN:3\n",
      "Fitting Parameter:800000, RUN:3\n",
      "Testing Parameter:800000, RUN:3\n",
      "10000/10000 [==============================] - 1s 146us/sample - loss: 0.0490 - accuracy: 0.7827\n",
      "Completed Parameter:800000, RUN:3\n",
      "Fitting Parameter:3000, RUN:4\n",
      "Testing Parameter:3000, RUN:4\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0693 - accuracy: 0.5180\n",
      "Completed Parameter:3000, RUN:4\n",
      "Fitting Parameter:5000, RUN:4\n",
      "Testing Parameter:5000, RUN:4\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0540 - accuracy: 0.6494\n",
      "Completed Parameter:5000, RUN:4\n",
      "Fitting Parameter:10000, RUN:4\n",
      "Testing Parameter:10000, RUN:4\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0443 - accuracy: 0.8073\n",
      "Completed Parameter:10000, RUN:4\n",
      "Fitting Parameter:20000, RUN:4\n",
      "Testing Parameter:20000, RUN:4\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0440 - accuracy: 0.8199\n",
      "Completed Parameter:20000, RUN:4\n",
      "Fitting Parameter:22000, RUN:4\n",
      "Testing Parameter:22000, RUN:4\n",
      "10000/10000 [==============================] - 1s 113us/sample - loss: 0.0437 - accuracy: 0.8333\n",
      "Completed Parameter:22000, RUN:4\n",
      "Fitting Parameter:25000, RUN:4\n",
      "Testing Parameter:25000, RUN:4\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0435 - accuracy: 0.8323\n",
      "Completed Parameter:25000, RUN:4\n",
      "Fitting Parameter:27000, RUN:4\n",
      "Testing Parameter:27000, RUN:4\n",
      "10000/10000 [==============================] - 1s 113us/sample - loss: 0.0442 - accuracy: 0.8268\n",
      "Completed Parameter:27000, RUN:4\n",
      "Fitting Parameter:30000, RUN:4\n",
      "Testing Parameter:30000, RUN:4\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 0.0443 - accuracy: 0.8259\n",
      "Completed Parameter:30000, RUN:4\n",
      "Fitting Parameter:32000, RUN:4\n",
      "Testing Parameter:32000, RUN:4\n",
      "10000/10000 [==============================] - 1s 113us/sample - loss: 0.0440 - accuracy: 0.8289\n",
      "Completed Parameter:32000, RUN:4\n",
      "Fitting Parameter:35000, RUN:4\n",
      "Testing Parameter:35000, RUN:4\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 0.0453 - accuracy: 0.8398\n",
      "Completed Parameter:35000, RUN:4\n",
      "Fitting Parameter:37000, RUN:4\n",
      "Testing Parameter:37000, RUN:4\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 0.0443 - accuracy: 0.8162\n",
      "Completed Parameter:37000, RUN:4\n",
      "Fitting Parameter:40000, RUN:4\n",
      "Testing Parameter:40000, RUN:4\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0444 - accuracy: 0.8252\n",
      "Completed Parameter:40000, RUN:4\n",
      "Fitting Parameter:50000, RUN:4\n",
      "Testing Parameter:50000, RUN:4\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0445 - accuracy: 0.8262\n",
      "Completed Parameter:50000, RUN:4\n",
      "Fitting Parameter:60000, RUN:4\n",
      "Testing Parameter:60000, RUN:4\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0435 - accuracy: 0.8422\n",
      "Completed Parameter:60000, RUN:4\n",
      "Fitting Parameter:70000, RUN:4\n",
      "Testing Parameter:70000, RUN:4\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0445 - accuracy: 0.8315\n",
      "Completed Parameter:70000, RUN:4\n",
      "Fitting Parameter:80000, RUN:4\n",
      "Testing Parameter:80000, RUN:4\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0443 - accuracy: 0.8306\n",
      "Completed Parameter:80000, RUN:4\n",
      "Fitting Parameter:100000, RUN:4\n",
      "Testing Parameter:100000, RUN:4\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0440 - accuracy: 0.8284\n",
      "Completed Parameter:100000, RUN:4\n",
      "Fitting Parameter:300000, RUN:4\n",
      "Testing Parameter:300000, RUN:4\n",
      "10000/10000 [==============================] - 1s 120us/sample - loss: 0.0466 - accuracy: 0.8284\n",
      "Completed Parameter:300000, RUN:4\n",
      "Fitting Parameter:800000, RUN:4\n",
      "Testing Parameter:800000, RUN:4\n",
      "10000/10000 [==============================] - 1s 140us/sample - loss: 0.0489 - accuracy: 0.8008\n",
      "Completed Parameter:800000, RUN:4\n",
      "Fitting Parameter:3000, RUN:5\n",
      "Testing Parameter:3000, RUN:5\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0685 - accuracy: 0.4916\n",
      "Completed Parameter:3000, RUN:5\n",
      "Fitting Parameter:5000, RUN:5\n",
      "Testing Parameter:5000, RUN:5\n",
      "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0527 - accuracy: 0.6937\n",
      "Completed Parameter:5000, RUN:5\n",
      "Fitting Parameter:10000, RUN:5\n",
      "Testing Parameter:10000, RUN:5\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0460 - accuracy: 0.8163\n",
      "Completed Parameter:10000, RUN:5\n",
      "Fitting Parameter:20000, RUN:5\n",
      "Testing Parameter:20000, RUN:5\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0447 - accuracy: 0.8356\n",
      "Completed Parameter:20000, RUN:5\n",
      "Fitting Parameter:22000, RUN:5\n",
      "Testing Parameter:22000, RUN:5\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0442 - accuracy: 0.8254\n",
      "Completed Parameter:22000, RUN:5\n",
      "Fitting Parameter:25000, RUN:5\n",
      "Testing Parameter:25000, RUN:5\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0439 - accuracy: 0.8354\n",
      "Completed Parameter:25000, RUN:5\n",
      "Fitting Parameter:27000, RUN:5\n",
      "Testing Parameter:27000, RUN:5\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0457 - accuracy: 0.8037\n",
      "Completed Parameter:27000, RUN:5\n",
      "Fitting Parameter:30000, RUN:5\n",
      "Testing Parameter:30000, RUN:5\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0445 - accuracy: 0.8194\n",
      "Completed Parameter:30000, RUN:5\n",
      "Fitting Parameter:32000, RUN:5\n",
      "Testing Parameter:32000, RUN:5\n",
      "10000/10000 [==============================] - 1s 101us/sample - loss: 0.0447 - accuracy: 0.8430\n",
      "Completed Parameter:32000, RUN:5\n",
      "Fitting Parameter:35000, RUN:5\n",
      "Testing Parameter:35000, RUN:5\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0434 - accuracy: 0.8214\n",
      "Completed Parameter:35000, RUN:5\n",
      "Fitting Parameter:37000, RUN:5\n",
      "Testing Parameter:37000, RUN:5\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 0.0435 - accuracy: 0.8315\n",
      "Completed Parameter:37000, RUN:5\n",
      "Fitting Parameter:40000, RUN:5\n",
      "Testing Parameter:40000, RUN:5\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 0.0443 - accuracy: 0.8262\n",
      "Completed Parameter:40000, RUN:5\n",
      "Fitting Parameter:50000, RUN:5\n",
      "Testing Parameter:50000, RUN:5\n",
      "10000/10000 [==============================] - 1s 101us/sample - loss: 0.0445 - accuracy: 0.8349\n",
      "Completed Parameter:50000, RUN:5\n",
      "Fitting Parameter:60000, RUN:5\n",
      "Testing Parameter:60000, RUN:5\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0460 - accuracy: 0.8240\n",
      "Completed Parameter:60000, RUN:5\n",
      "Fitting Parameter:70000, RUN:5\n",
      "Testing Parameter:70000, RUN:5\n",
      "10000/10000 [==============================] - 1s 101us/sample - loss: 0.0445 - accuracy: 0.8168\n",
      "Completed Parameter:70000, RUN:5\n",
      "Fitting Parameter:80000, RUN:5\n",
      "Testing Parameter:80000, RUN:5\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0442 - accuracy: 0.8229\n",
      "Completed Parameter:80000, RUN:5\n",
      "Fitting Parameter:100000, RUN:5\n",
      "Testing Parameter:100000, RUN:5\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0455 - accuracy: 0.8355\n",
      "Completed Parameter:100000, RUN:5\n",
      "Fitting Parameter:300000, RUN:5\n",
      "Testing Parameter:300000, RUN:5\n",
      "10000/10000 [==============================] - 1s 121us/sample - loss: 0.0460 - accuracy: 0.8200\n",
      "Completed Parameter:300000, RUN:5\n",
      "Fitting Parameter:800000, RUN:5\n",
      "Testing Parameter:800000, RUN:5\n",
      "10000/10000 [==============================] - 1s 139us/sample - loss: 0.0465 - accuracy: 0.8335\n",
      "Completed Parameter:800000, RUN:5\n"
     ]
    }
   ],
   "source": [
    "training_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "for run in range(1,6):\n",
    "    training_loss = []\n",
    "    test_loss = []\n",
    "    training_dict  = {}\n",
    "    test_dict  = {}\n",
    "    for parameters in parameter_size:\n",
    "        train_loss = tf.keras.losses.MeanSquaredError(name = \"train_loss\")\n",
    "        sgd_optimizer = tf.keras.optimizers.SGD(momentum=0.95)\n",
    "        #Gives number of units from number of weights\n",
    "        units = tl.get_number_units(parameters, input_size = input_size, output_size = num_classes)\n",
    "        network = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(units=units, activation = None),\n",
    "        tf.keras.layers.Dense(units=num_classes,  activation = None)])\n",
    "        #Training\n",
    "        network.compile(optimizer = sgd_optimizer, loss = train_loss , metrics = ['accuracy'])\n",
    "        print(\"Fitting Parameter:{}, RUN:{}\".format(parameters,run))\n",
    "        if units < interpol_threshold:\n",
    "            history = network.fit(x=x_train, y=y_train, callbacks=[earlystop_callback,lr_schedule], epochs=total_epochs, verbose = 0)\n",
    "        else:\n",
    "            history = network.fit(x=x_train, y=y_train, epochs=total_epochs, verbose = 0)\n",
    "        training_loss.append(history.history[\"loss\"][-1])\n",
    "        print(\"Testing Parameter:{}, RUN:{}\".format(parameters,run))\n",
    "        results = network.evaluate(x_test, y_test)\n",
    "        test_loss.append(results[0])\n",
    "        print(\"Completed Parameter:{}, RUN:{}\".format(parameters,run))\n",
    "    training_df[str(run)] = training_loss\n",
    "    test_df[str(run)] = test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(parameter_size, training_df.mean(axis=1), label=\"Training\", marker=\"o\")\n",
    "plt.plot(parameter_size, test_df.mean(axis=1), label=\"Test\", marker=\"o\")\n",
    "plt.yscale(value=\"log\")\n",
    "plt.legend()\n",
    "plt.xscale(value=\"log\")\n",
    "x_lbl = plt.xlabel(\"Number of Weights\")\n",
    "#y_lbl = plt.ylabel(\"Squared Loss\")\n",
    "plt.xlim(xmin=0)\n",
    "plt.axvline(x=40000, linestyle=\"--\", color = \"black\")\n",
    "plt.title(\"Without Weight Reuse\")\n",
    "plt.savefig(\"without_reuse.png\",bbox_extra_artists=[y_lbl,x_lbl], dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
